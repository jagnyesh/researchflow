# LangChain/LangGraph Orchestrator (Experimental)

üöß **Status:** Experimental - Proof of Concept
üéØ **Purpose:** Evaluate Lang Chain/LangGraph as alternative to custom orchestrator

---

## Overview

This directory contains an experimental implementation of ResearchFlow's orchestrator using Lang Chain and LangGraph. This is a **parallel implementation** that runs alongside the existing custom orchestrator for comparison.

**Goal:** Determine if LangChain/LangGraph provides advantages over our custom solution.

---

## Architecture

### Current Custom Orchestrator (Baseline)

```
app/orchestrator/
‚îú‚îÄ‚îÄ orchestrator.py           # A2A coordinator (500+ lines)
‚îî‚îÄ‚îÄ workflow_engine.py         # 15-state FSM (300+ lines)

app/agents/
‚îú‚îÄ‚îÄ base_agent.py             # Base class with retry logic
‚îú‚îÄ‚îÄ requirements_agent.py
‚îú‚îÄ‚îÄ phenotype_agent.py
‚îî‚îÄ‚îÄ ... (4 more agents)
```

### LangChain Alternative (Experimental)

```
app/langchain_orchestrator/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ README.md                  # This file
‚îú‚îÄ‚îÄ langgraph_workflow.py      # StateGraph (15 states)
‚îú‚îÄ‚îÄ langchain_agents.py        # Agent adapters
‚îú‚îÄ‚îÄ tools.py                   # MCP tool integrations
‚îî‚îÄ‚îÄ comparison.md              # Findings vs custom
```

---

## Key Questions to Answer

### 1. Code Complexity
- **Q:** Is LangGraph simpler than custom FSM?
- **Metric:** Lines of code, conceptual complexity

### 2. Performance
- **Q:** Does LangChain add overhead?
- **Metric:** Agent execution time, state transition latency

### 3. Maintainability
- **Q:** Is it easier to debug/extend with LangChain?
- **Metric:** Developer experience, tooling quality

### 4. Feature Parity
- **Q:** Can LangGraph support all our features?
- **Required:**
  - 15-state workflow
  - Human-in-loop approvals
  - Database persistence
  - Conditional routing
  - Error handling

---

## Implementation Approach

### Phase 1: Single Agent Prototype

**Goal:** Test LangChain concepts with 1 agent

**Files to Create:**
- `langchain_agents.py` - Requirements Agent wrapper
- `simple_workflow.py` - 3-state StateGraph

**What We're Testing:**
- LangChain AgentExecutor
- Tool calling
- Memory/conversation history
- LangGraph state transitions

### Phase 2: Full Workflow

**Goal:** Implement complete 15-state workflow

**Files to Create:**
- `langgraph_workflow.py` - Full StateGraph
- `tools.py` - MCP server tools
- `persistence.py` - Database integration

**What We're Testing:**
- All 6 agents
- Conditional routing
- Human-in-loop nodes
- Error handling
- Database persistence

### Phase 3: Comparison

**Goal:** Benchmark and decide

**Files to Create:**
- `comparison.md` - Findings document
- `benchmarks/` - Performance tests

**What We're Testing:**
- Side-by-side execution
- Performance metrics
- Code maintainability
- Migration effort

---

## Dependencies

```python
# Installed in feature branch
langchain>=1.0.0
langchain-core>=1.0.0
langchain-community>=0.4
langchain-anthropic>=1.0.0
langgraph>=1.0.0
langsmith>=0.4.0
```

---

## Usage

### Running Custom Orchestrator (Baseline)

```python
from app.orchestrator.orchestrator import ResearchRequestOrchestrator

orchestrator = ResearchRequestOrchestrator()
request_id = await orchestrator.process_new_request(
    researcher_request="I need diabetes patients...",
    researcher_info={...}
)
```

### Running LangChain Orchestrator (Experimental)

```python
# TBD - Will be similar API
from app.langchain_orchestrator import LangGraphOrchestrator

orchestrator = LangGraphOrchestrator()
request_id = await orchestrator.process_new_request(
    researcher_request="I need diabetes patients...",
    researcher_info={...}
)
```

---

## Comparison Metrics

We'll compare on these dimensions:

| Metric | Custom | LangChain | Winner |
|--------|--------|-----------|--------|
| Lines of Code | ~1000 | TBD | TBD |
| Execution Time | TBD | TBD | TBD |
| Memory Usage | TBD | TBD | TBD |
| Debug Ease | ‚≠ê‚≠ê‚≠ê | TBD | TBD |
| Maintainability | ‚≠ê‚≠ê‚≠ê | TBD | TBD |
| Learning Curve | Low | Medium | TBD |

---

## Decision Framework

**Migrate to LangChain IF:**
- ‚úÖ 30%+ code reduction
- ‚úÖ Better observability (LangSmith)
- ‚úÖ Equivalent performance
- ‚úÖ Feature parity

**Keep Custom IF:**
- ‚ùå Significant overhead
- ‚ùå Performance degradation
- ‚ùå Missing critical features
- ‚ùå High migration cost

**Hybrid Approach IF:**
- üîÑ Mix of both provides best results

---

## Testing

### Custom Orchestrator Tests (Baseline)

```bash
# All 21 tests passing
pytest tests/test_nlp_to_sql_workflow.py -v
pytest tests/test_admin_dashboard_updates.py -v
```

### LangChain Tests (To Be Created)

```bash
pytest tests/test_langchain_orchestrator.py -v
pytest tests/test_langgraph_workflow.py -v
```

---

## Documentation

- **Evaluation Plan:** `docs/LANGCHAIN_EVALUATION.md`
- **LangChain Docs:** https://python.langchain.com/
- **LangGraph Docs:** https://langchain-ai.github.io/langgraph/
- **Our Custom Orchestrator:** `docs/RESEARCHFLOW_README.md`

---

## Status

- [x] Feature branch created
- [x] Dependencies installed
- [x] Directory structure created
- [ ] Requirements Agent prototype
- [ ] Simple 3-state workflow
- [ ] Full 15-state workflow
- [ ] Performance benchmarks
- [ ] Comparison document
- [ ] Final recommendation

---

**Created:** 2025-10-25
**Branch:** `feature/langchain-langgraph-exploration`
**Status:** üöß Experimental
