# ResearchFlow Environment Configuration

# Required: Anthropic API Key for LLM features (used for critical medical tasks)
ANTHROPIC_API_KEY=sk-ant-your-key-here

# Optional: Secondary LLM Provider for non-critical tasks (calendar, delivery)
# Options: openai, ollama, anthropic (default: anthropic)
SECONDARY_LLM_PROVIDER=anthropic

# Optional: OpenAI API Key (only needed if SECONDARY_LLM_PROVIDER=openai)
OPENAI_API_KEY=sk-your-openai-key-here

# Optional: Ollama Base URL (only needed if SECONDARY_LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434

# Optional: Default model for secondary provider
# Examples: gpt-4o, gpt-4-turbo (OpenAI) | llama3, mistral (Ollama)
SECONDARY_LLM_MODEL=

# Optional: Enable automatic fallback to Claude if secondary provider fails
ENABLE_LLM_FALLBACK=true

# Optional: Database URL (defaults to SQLite if not set)
DATABASE_URL=sqlite+aiosqlite:///./dev.db
# For PostgreSQL: postgresql+asyncpg://user:password@localhost/dbname
# Docker setup: postgresql+asyncpg://postgres:postgres@localhost:5432/fhir_db

# Optional: FHIR Server URL (for SQL-on-FHIR operations)
FHIR_SERVER_URL=http://localhost:8081/fhir
# Docker internal: http://hapi-fhir:8080/fhir

# Optional: JWT Secret for A2A authentication
A2A_JWT_SECRET=devsecret

# ============================================================================
# LANGSMITH OBSERVABILITY (Sprint 5)
# ============================================================================
# Enable LangSmith tracing for workflow observability
# Get API key from: https://smith.langchain.com/settings
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=<your-langsmith-api-key>
LANGCHAIN_PROJECT=researchflow-production

# Optional: Additional LangSmith configuration
# LANGSMITH_TAGS=production,langgraph,research
# LANGCHAIN_HUB_API_URL=https://api.hub.langchain.com

# ============================================================================
# REDIS SPEED LAYER (Sprint 5.5)
# ============================================================================
# Redis URL for Lambda architecture speed layer
# Docker: redis://redis:6379/0
# Local: redis://localhost:6379/0
REDIS_URL=redis://localhost:6379/0

# Enable/disable speed layer queries (set to false to disable Redis)
USE_SPEED_LAYER=true
