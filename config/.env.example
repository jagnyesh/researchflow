# ResearchFlow Environment Configuration

# Required: Anthropic API Key for LLM features (used for critical medical tasks)
ANTHROPIC_API_KEY=sk-ant-your-key-here

# Optional: Secondary LLM Provider for non-critical tasks (calendar, delivery)
# Options: openai, ollama, anthropic (default: anthropic)
SECONDARY_LLM_PROVIDER=anthropic

# Optional: OpenAI API Key (only needed if SECONDARY_LLM_PROVIDER=openai)
OPENAI_API_KEY=sk-your-openai-key-here

# Optional: Ollama Base URL (only needed if SECONDARY_LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434

# Optional: Default model for secondary provider
# Examples: gpt-4o, gpt-4-turbo (OpenAI) | llama3, mistral (Ollama)
SECONDARY_LLM_MODEL=

# Optional: Enable automatic fallback to Claude if secondary provider fails
ENABLE_LLM_FALLBACK=true

# Optional: Database URL (defaults to SQLite if not set)
DATABASE_URL=sqlite+aiosqlite:///./dev.db
# For PostgreSQL: postgresql+asyncpg://user:password@localhost/dbname
# Docker setup: postgresql+asyncpg://postgres:postgres@localhost:5432/fhir_db

# Optional: FHIR Server URL (for SQL-on-FHIR operations)
FHIR_SERVER_URL=http://localhost:8081/fhir
# Docker internal: http://hapi-fhir:8080/fhir

# Optional: JWT Secret for A2A authentication
A2A_JWT_SECRET=devsecret
