# LangSmith Observability Dashboard Guide

**Sprint 5 Deliverable** | **Updated:** 2025-10-26

This guide explains how to use the LangSmith dashboard to monitor and debug your ResearchFlow LangGraph workflow.

---

## Table of Contents

1. [Getting Started](#getting-started)
2. [Dashboard Overview](#dashboard-overview)
3. [Finding Your Traces](#finding-your-traces)
4. [Understanding Trace Hierarchy](#understanding-trace-hierarchy)
5. [Key Metrics to Monitor](#key-metrics-to-monitor)
6. [Filtering and Searching](#filtering-and-searching)
7. [Debugging with Traces](#debugging-with-traces)
8. [Cost Tracking](#cost-tracking)
9. [Best Practices](#best-practices)

---

## Getting Started

### Accessing LangSmith

1. **Visit:** https://smith.langchain.com
2. **Sign in** with your account
3. **Navigate to:** Projects â†’ `researchflow-production`

### Project Configuration

Your ResearchFlow traces are sent to the `researchflow-production` project, configured in `.env`:

```bash
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=researchflow-production
LANGCHAIN_API_KEY=lsv2_pt_...
```

---

## Dashboard Overview

### Main Dashboard Elements

When you open the `researchflow-production` project, you'll see:

1. **Run Count** - Total number of workflow executions
2. **Error Rate** - Percentage of failed runs (target: 0%)
3. **P50/P99 Latency** - Performance metrics (median and 99th percentile)
4. **Recent Runs** - List of latest workflow executions
5. **Feedback** - User-provided ratings (if configured)

### Project View

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  researchflow-production                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Runs: 42    Error Rate: 2.4%    P50: 1.2s   P99: 7.8s â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Recent Runs:                                           â”‚
â”‚  âœ… ResearchFlow_FullWorkflow  2025-10-26 14:37  0.09s  â”‚
â”‚  âœ… ResearchFlow_FullWorkflow  2025-10-26 13:22  0.11s  â”‚
â”‚  âŒ ResearchFlow_FullWorkflow  2025-10-26 12:15  2.34s  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Finding Your Traces

### Identifying Workflow Runs

Each workflow execution creates a top-level trace with:

- **Name:** `ResearchFlow_FullWorkflow`
- **Type:** Chain
- **Tags:** `workflow`, `langgraph`, `research`
- **Environment Tag:** `e2e-test` OR `production`

### Request ID Mapping

Each trace includes metadata with the ResearchFlow request ID:

```json
{
  "request_id": "REQ-E2E-1761507426",
  "initial_state": "new_request",
  "researcher": "Dr. Smith",
  "timestamp": "2025-10-26T14:37:06.174669"
}
```

Use this to correlate LangSmith traces with requests in your database.

---

## Understanding Trace Hierarchy

### 3-Level Trace Architecture

ResearchFlow uses hierarchical tracing:

```
Level 1: Workflow Trace
â””â”€â”€ ResearchFlow_FullWorkflow (@traceable on run() method)
    â”‚
    â”œâ”€â”€ Level 2: Agent Traces
    â”‚   â”œâ”€â”€ RequirementsAgent (@traceable on execute_task())
    â”‚   â”‚   â””â”€â”€ Level 3: LLM Calls
    â”‚   â”‚       â””â”€â”€ ChatAnthropic.ainvoke() [auto-traced]
    â”‚   â”‚
    â”‚   â”œâ”€â”€ PhenotypeAgent (@traceable on execute_task())
    â”‚   â”‚   â””â”€â”€ ChatAnthropic.ainvoke() [auto-traced]
    â”‚   â”‚
    â”‚   â”œâ”€â”€ CalendarAgent (@traceable on execute_task())
    â”‚   â”œâ”€â”€ ExtractionAgent (@traceable on execute_task())
    â”‚   â”œâ”€â”€ QAAgent (@traceable on execute_task())
    â”‚   â””â”€â”€ DeliveryAgent (@traceable on execute_task())
    â”‚       â””â”€â”€ ChatAnthropic.ainvoke() [auto-traced]
```

### Example Trace View

When you click on a workflow trace, you'll see:

```
ResearchFlow_FullWorkflow (90ms) âœ…
â”œâ”€ RequirementsAgent (45ms) âœ…
â”‚  â””â”€ ChatAnthropic (42ms) âœ…
â”‚     Input: 3,245 tokens
â”‚     Output: 512 tokens
â”‚     Cost: $0.0234
â”œâ”€ PhenotypeAgent (12ms) âœ…
â”‚  â””â”€ ChatAnthropic (10ms) âœ…
â”‚     Input: 2,100 tokens
â”‚     Output: 324 tokens
â”‚     Cost: $0.0156
â”œâ”€ CalendarAgent (8ms) âœ…
â”œâ”€ ExtractionAgent (6ms) âœ…
â”œâ”€ QAAgent (5ms) âœ…
â””â”€ DeliveryAgent (14ms) âœ…
   â””â”€ ChatAnthropic (11ms) âœ…
      Input: 1,850 tokens
      Output: 278 tokens
      Cost: $0.0142
```

---

## Key Metrics to Monitor

### 1. Workflow Performance

**Where:** Top-level `ResearchFlow_FullWorkflow` trace

**Metrics:**
- **Duration:** Total workflow execution time (target: < 10 seconds)
- **Status:** Success/Failure
- **State Transitions:** Number of states executed (typical: 8-11 states)

**What to Watch:**
- âš ï¸ Duration > 30 seconds â†’ Investigate slow agents
- âŒ Failure rate > 5% â†’ Check error logs
- ğŸ” State count anomalies â†’ Workflow logic issues

### 2. Agent Performance

**Where:** Individual agent traces (RequirementsAgent, PhenotypeAgent, etc.)

**Metrics:**
- **Agent Duration:** Time spent in each agent (typical: 5-50ms for non-LLM agents)
- **Task Success Rate:** Percentage of successful agent executions
- **Error Messages:** Exception details if agent fails

**What to Watch:**
- âš ï¸ RequirementsAgent > 60s â†’ LLM timeout or complex conversation
- âš ï¸ PhenotypeAgent > 30s â†’ SQL generation taking too long
- âŒ Agent errors â†’ Check agent logs for root cause

### 3. LLM Usage & Costs

**Where:** `ChatAnthropic` child traces (auto-traced by LangChain)

**Metrics:**
- **Token Counts:** Input + Output tokens per call
- **Cost:** Per-call and cumulative costs
- **Latency:** LLM API response time
- **Model:** Which Claude model was used

**What to Watch:**
- ğŸ’° Cost > $1 per workflow â†’ Optimize prompts or use smaller models
- âš ï¸ Input tokens > 10,000 â†’ Context too large, consider summarization
- ğŸ• Latency > 20s â†’ API throttling or network issues

### 4. Error Tracking

**Where:** Failed traces (marked with âŒ)

**Information Captured:**
- **Exception Type:** Python exception class
- **Stack Trace:** Full traceback for debugging
- **State at Failure:** Which workflow state caused the error
- **Request Context:** request_id, researcher, requirements

**What to Watch:**
- ğŸ” Repeated errors â†’ Systemic issue requiring code fix
- ğŸ” Intermittent failures â†’ Network or API issues
- ğŸ” Terminal states (`not_feasible`, `qa_failed`) â†’ Expected workflow outcomes

---

## Filtering and Searching

### Using Tags

ResearchFlow uses consistent tagging for easy filtering:

**Filter by Environment:**
```
Tag: e2e-test     â†’ E2E test runs only
Tag: production   â†’ Production workflow runs
```

**Filter by Component:**
```
Tag: workflow     â†’ Top-level workflow traces
Tag: agent        â†’ Agent-level traces
Tag: requirements â†’ Requirements Agent only
Tag: phenotype    â†’ Phenotype Agent only
Tag: llm          â†’ LLM-based agents only
```

### Advanced Filters

**Time Range:**
- Last 1 hour â†’ Recent test runs
- Last 24 hours â†’ Daily monitoring
- Last 7 days â†’ Weekly trends

**Status:**
- Success only â†’ Healthy workflows
- Errors only â†’ Debugging failures
- By duration â†’ Performance issues

**Metadata Search:**
```
request_id: "REQ-12345"         â†’ Find specific request
researcher: "Dr. Smith"         â†’ Filter by researcher
initial_state: "new_request"    â†’ Workflow entry point
```

---

## Debugging with Traces

### Scenario 1: Workflow Fails at Feasibility Stage

**Steps:**
1. Filter traces by Tag: `phenotype` and Status: `error`
2. Click on failed PhenotypeAgent trace
3. Expand to see:
   - Input context (requirements)
   - SQL generation output
   - Error stack trace
4. Check metadata for `estimated_cohort_size` and `feasible` flag
5. Investigate:
   - Was SQL invalid? â†’ Check SQL generator logic
   - Was cohort size = 0? â†’ Requirements too restrictive
   - Did LLM timeout? â†’ Check LLM latency metrics

### Scenario 2: Slow Workflow Execution

**Steps:**
1. Find slow trace (duration > 30s)
2. Expand full trace hierarchy
3. Sort child traces by duration (longest first)
4. Identify bottleneck:
   - If RequirementsAgent is slow â†’ LLM conversation taking too long
   - If ExtractionAgent is slow â†’ Data retrieval issue (FHIR API, DB query)
   - If QAAgent is slow â†’ Large dataset validation
5. Optimize the bottleneck component

### Scenario 3: Unexpected State Transitions

**Steps:**
1. Find trace with unexpected final state
2. Check metadata:
   - `current_state`: Final workflow state
   - `initial_state`: Starting state
3. Look for:
   - Terminal states (`not_feasible`, `qa_failed`) â†’ Expected workflow outcomes
   - Approval gates â†’ Check `*_approved` flags in metadata
4. Review routing logic in `langgraph_workflow.py`

---

## Cost Tracking

### Viewing LLM Costs

**Per-Trace Costs:**
1. Click on workflow trace
2. Expand LLM child traces (`ChatAnthropic`)
3. Each trace shows:
   - Input tokens Ã— rate
   - Output tokens Ã— rate
   - Total cost for that call

**Cumulative Costs:**
- LangSmith automatically sums costs across all LLM calls in a trace
- View totals at the workflow level

### Cost Optimization Tips

**1. Reduce Token Usage:**
- âœ… Use smaller prompts (remove unnecessary context)
- âœ… Summarize long conversation histories
- âœ… Use structured outputs instead of verbose responses

**2. Use Appropriate Models:**
- âœ… Critical tasks (Requirements, Phenotype) â†’ Claude 3.5 Sonnet
- âœ… Non-critical tasks (Calendar, Delivery) â†’ Cheaper models (Haiku, Ollama)
- âœ… Enable multi-provider LLM fallback (already configured)

**3. Batch Operations:**
- âœ… Combine multiple small LLM calls into one larger call
- âœ… Cache frequently used prompts/responses

**Expected Costs:**
- Typical workflow: $0.05 - $0.15 per request
- Complex conversations: $0.20 - $0.50 per request
- Monthly (1000 requests): $50 - $150

---

## Best Practices

### 1. Tagging Strategy

**Always Include:**
- Environment tag (`e2e-test` or `production`)
- Component type tag (`workflow`, `agent`)
- Specific agent tag (`requirements`, `phenotype`, etc.)

**Optional Tags:**
- User ID or researcher name
- Feature flags (`multi-llm-enabled`, `cache-enabled`)
- Deployment version (`v1.0.0`, `staging`)

### 2. Metadata Best Practices

**Include in Workflow Metadata:**
- `request_id`: Unique request identifier
- `researcher`: Researcher name or ID
- `timestamp`: Execution start time
- `version`: Workflow version
- `duration_ms`: Total execution time

**Include in Agent Metadata:**
- `agent_type`: Agent category
- `task`: Task being executed
- `llm`: Model used (if LLM-based)
- `capability`: Agent capability description

### 3. Monitoring Cadence

**Daily:**
- Check error rate (target: < 2%)
- Review slow workflows (> 30s)
- Monitor LLM costs (daily budget)

**Weekly:**
- Analyze P50/P99 latency trends
- Review most expensive workflows
- Identify optimization opportunities

**Monthly:**
- Cumulative cost analysis
- Performance regression testing
- User feedback correlation

### 4. Alert Setup (Future Enhancement)

**Recommended Alerts:**
- âŒ Error rate > 5% in last hour
- â±ï¸ P99 latency > 60 seconds
- ğŸ’° Daily cost > $100
- ğŸ”¥ Specific agent failure rate > 10%

**How to Set Up:**
1. LangSmith Settings â†’ Alerts
2. Configure threshold and notification channel
3. Test alert with intentional failure

---

## Troubleshooting

### Traces Not Appearing

**Issue:** No traces showing up in `researchflow-production` project

**Solutions:**
1. Check `.env` configuration:
   ```bash
   LANGCHAIN_TRACING_V2=true
   LANGCHAIN_PROJECT=researchflow-production
   LANGCHAIN_API_KEY=lsv2_pt_...
   ```
2. Verify API key is valid (test with `langsmith.Client()`)
3. Check for firewall blocking `api.smith.langchain.com`
4. Wait 5-10 seconds for traces to appear (async upload)
5. Refresh dashboard page

### Missing LLM Traces

**Issue:** Agent traces appear but no LLM child traces

**Solutions:**
1. Ensure `LANGCHAIN_TRACING_V2=true` is set BEFORE importing LangChain
2. Verify using `ChatAnthropic` from `langchain_anthropic`
3. Check that LLM is actually being called (not cached/mocked)

### High Costs

**Issue:** LLM costs higher than expected

**Solutions:**
1. Review token counts per trace
2. Check for repeated/redundant LLM calls
3. Optimize prompts to reduce input tokens
4. Use cheaper models for non-critical tasks
5. Enable caching for repeated queries

---

## Next Steps

### Explore Advanced Features

1. **Custom Dashboards** - Create project-specific views
2. **Datasets** - Save test cases for regression testing
3. **Evaluators** - Automate quality checks on LLM outputs
4. **Feedback** - Collect user ratings on workflow results
5. **Annotations** - Add notes to traces for team collaboration

### Resources

- **LangSmith Docs:** https://docs.smith.langchain.com
- **LangChain Tracing:** https://python.langchain.com/docs/langsmith/walkthrough
- **ResearchFlow Architecture:** `docs/RESEARCHFLOW_README.md`
- **Sprint 5 Plan:** `docs/sprints/SPRINT_05_LANGSMITH_OBSERVABILITY.md`

---

## Summary

LangSmith provides comprehensive observability for your ResearchFlow workflow:

âœ… **Workflow Visibility** - See every execution from start to finish
âœ… **Agent Performance** - Track individual agent execution times
âœ… **LLM Monitoring** - Monitor token usage, costs, and latency
âœ… **Error Tracking** - Debug failures with full stack traces
âœ… **Cost Control** - Understand and optimize LLM expenses

**Key Takeaway:** Use LangSmith daily to monitor production workflows and ensure ResearchFlow is running smoothly and cost-effectively.

---

**Updated:** 2025-10-26 | **Sprint:** 5 | **Status:** âœ… Complete
